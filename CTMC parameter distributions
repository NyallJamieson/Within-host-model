# Code for obtaining distributions for each parameter to be used within the CTMC model.

l <- read.csv("lambda_data.csv",header=FALSE)
time <- l[,2]
prop <- l[,1]
pred_frame <- seq(1,72,by=1)
pred_frame <- data.frame(pred_frame)
death_prop <- prop/100
death_cdf <- death_prop/death_prop[72]
pburrNEW <- function(x,a,b,T){(1+(T/x)^(a)*exp((T-x)/b))^(-1)}

# Lambda
####################################################
# ci for lambda is obtained by method called non-parametric bootsrapping
part1 <- function(y){
u <- runif(n=1000)
samp <- c()
for (i in u){
val <- uniroot(function(x) pburrNEW(x,a=0.6327,b=11.0200,T=21.7964)-i,lower=0,upper=500)$root
samp <- append(samp,val)
}
return(unname(1/quantile(samp,probs=0.5/death_prop[72])))
}
lambda_dist <- as.numeric(parallel::mclapply(1:10000,part1,mc.cores=parallel::detectCores()))
####################################################


# Include T to finalise
####################################################
time <- c(2,24,48,72)
logdose <- log(c(13584.15,588828.58,11207102.05,82907236.06))
L0 <- 10^5
yourdata2 <- data.frame(time,dose)
# Now stick in other parameters (also calculate theta, x1, C, T)

results <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(results) <- c("alpha_dist","beta_dist","G_dist","h_dist","A_dist","w_dist")


part2 <- function(y){
h <- sample(size=1,lambda_dist,replace=TRUE)
A_w <- MASS::mvrnorm(n=1,mu=c(177.95295,0.19242),Sigma=matrix(c(82.49019097,-0.0254690939,-0.0254690939,0.0001933546),2,2))
A <- A_w[1]
w <- A_w[2]
G <- A/(1+(A-1)*exp(-w*(1/h-1)))

reps <- 500
ab_model <- minpack.lm::nlsLM(logdose~log(L0)-0.5*log((h-gamma)^2+4*h*Pi*gamma*G)+log(0.5*(h-gamma+((h-gamma)^2+4*h*gamma*Pi*G)^0.5)*exp(0.5*time*(-h-gamma+((h-gamma)^2+4*h*gamma*Pi*G)^0.5))-0.5*(h-gamma-((h-gamma)^2+4*h*gamma*Pi*G)^0.5)*exp(0.5*time*(-h-gamma-((h-gamma)^2+4*h*gamma*Pi*G)^0.5))),start=list(gamma=5,Pi=0.5),lower=c(0,0))
ab <- data.frame(MASS::mvrnorm(n=reps,mu=c(coef(ab_model)[1],coef(ab_model)[2]),Sigma=matrix(c(vcov(ab_model)[1],vcov(ab_model)[2],vcov(ab_model)[3],vcov(ab_model)[4]),2,2)))


alpha_dist <- ab[,1]*ab[,2]
beta_dist <- ab[,1]*(1-ab[,2])
G_dist <- rep(G,reps)
h_dist <- rep(h,reps)
A_dist <- rep(A,reps)
w_dist <- rep(w,reps)
return(data.frame(alpha_dist,beta_dist,G_dist,h_dist,A_dist,w_dist))
}

results <- dplyr::bind_rows(results,as.data.frame(na.omit(do.call(rbind,parallel::mclapply(1:10000,part2,mc.cores=parallel::detectCores())),na.action="omit")))
######################################################
# remove dodgy results and save
alpha_dist <- results[,1]
beta_dist <- results[,2]
int1 <- which(alpha_dist>0)
int2 <- which(beta_dist>0)
int3 <- intersect(int1,int2)

results <- results[int3,]
######################################################
# this is to repeat all rows so that we can sample C 100 times from normal distribution to incorporate uncertainty
Repeated <- results |> dplyr::slice(rep(1:nrow(results), each = 100))

alpha <- results[,1]
beta <- results[,2]
G <- results[,3]
h <- results[,4]
theta <- sqrt((h-alpha-beta)^2+4*h*alpha*G)
x1 <- 0.5*(-h-alpha-beta+theta)


d3 <- c(4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,4*10^5,5*10^4,5*10^4,5*10^4,5*10^4,4*10^3,4*10^3,4*10^3,4*10^3,4*10^3,4*10^3,4*10^3,4*10^3,4*10^3,4*10^3,2*10^2,2*10^2,2*10^2,2*10^2,2*10^2,2*10^2,2*10^2,2*10^2,2*10^2,2*10^2)
t3 <- 24*c(1,1,1,1,1,1,1,1,1,2,2,2,1,2,2,2,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4)
t_L <- t3-24
t_R <- t3

C_vec <- data.frame(matrix(ncol = 1, nrow = 0))
colnames(C_vec)="C_dist"

part3 <- function(y){
x2 <- x1[y]
rhs <- log(d3)/x2
left <- t_L+rhs
right <- t_R+rhs
Data <- data.frame(left,right)
# Create an interval-censored survival object
surv_obj <- survival::Surv(time = left, time2 = right, type = "interval2")
model <- survival::survreg(surv_obj ~ 1, data = Data, dist = "gaussian")
return(rnorm(n=100,mean=unname(coef(model)),sd=unname(predict(model,se.fit=TRUE)$se.fit[1])))
}
C <- unlist(parallel::mclapply(1:length(x1),part3,mc.cores=parallel::detectCores()))

Repeated <- Repeated |> tidyr::drop_na()
Repeated <- Repeated[which(!is.na(C)),]
results2 <- Repeated
results3 <- data.frame(results2,na.omit(C))

theta <- sqrt((results3[,4]-results3[,1]-results3[,2])^2+4*results3[,4]*results3[,1]*results3[,3])
x1 <- 0.5*(-results3[,4]-results3[,1]-results3[,2]+theta)
phi <- rbeta(n=nrow(results3),shape=191.18,shape2=577.26)
T <- phi*(x1+results3[,4])*exp(results3[,7]*x1)/theta

results3 <- results3 |> dplyr::mutate("phi"=phi)
results3 <- results3 |> dplyr::mutate("T"=T)
results3 <- results3 |> tidyr::drop_na()


# plots now for parameter distributions

ker_alpha <- density(results3$alpha_dist)
plot(ker_alpha,xlab=expression(alpha),main=expression("Distribution of "* alpha))
polygon(ker_alpha,col="skyblue")

ker_beta <- density(results3$beta_dist)
plot(ker_beta,xlab=expression(beta),main=expression("Distribution of "* beta))
polygon(ker_beta,col="skyblue")

ker_G <- density(results3$G_dist,"bw"=2)
plot(ker_G,xlab="G",main="Distribution of G")
polygon(ker_G,col="skyblue")

ker_lambda <- density(results3$h_dist,"bw"=0.0002)
plot(ker_lambda,xlab=expression(lambda),main=expression("Distribution of "* lambda))
polygon(ker_lambda,col="skyblue")

ker_A <- density(results3$A_dist,"bw"=1)
plot(ker_A,xlab=expression(psi),main=expression("Distribution of "* psi))
polygon(ker_A,col="skyblue")

ker_omega <- density(results3$w_dist,"bw"=0.002)
plot(ker_omega,xlab=expression(omega),main=expression("Distribution of A"* omega))
polygon(ker_omega,col="skyblue")

C2 <- results3[which(results3[,7]<200),7]
ker_C <- density(C2)
plot(ker_C,xlab="C",main="Distribution of C")
polygon(ker_C,col="skyblue")

ker_phi <- density(results3$phi,"bw"=0.0001)
plot(ker_phi,xlab=expression(phi),main=expression("Distribution of "* phi))
polygon(ker_phi,col="skyblue")

ker_T <- density(results3$T,"bw"=2)
plot(ker_T,xlab="T",main="Distribution of T")
polygon(ker_T,col="skyblue")
